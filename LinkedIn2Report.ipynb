{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muratcankoylan/linkedin-analyzer/blob/main/LinkedIn2Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v7p5lwm45vr"
      },
      "source": [
        "# LinkedIn Profile Analyzer\n",
        "\n",
        "This Colab notebook is designed to analyze LinkedIn profiles by fetching user details and posts via LinkedIn's API. It then performs a detailed analysis using a custom AI model hosted by OpenRouter.\n",
        "\n",
        "## Purpose\n",
        "\n",
        "The purpose of this notebook is to provide insights into the professional background, engagement levels, and areas of expertise of LinkedIn users, which can be particularly useful for creatives, professionals, marketers, or personal branding experts.\n",
        "\n",
        "## How It Works\n",
        "\n",
        "1. The notebook retrieves user details and their latest posts from LinkedIn.\n",
        "2. It constructs a comprehensive prompt with these details and asks an AI model to analyze the content.\n",
        "3. The AI model evaluates the posts to provide insights on professional interests, skills, trends in discussion topics, and recommendations for professional growth.\n",
        "\n",
        "## API Key and Sensitive Data\n",
        "\n",
        "- **OPENROUTER_API_KEY**: This is a placeholder for the actual API key used to authenticate requests to OpenRouter's AI service.\n",
        "- **Rapid API Linkedin Key**: https://rapidapi.com/freshdata-freshdata-default/api/fresh-linkedin-profile-data\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1. Replace `OPENROUTER_API_KEY` with your actual OpenRouter API key.\n",
        "2. Replace Rapid API key placeholders with your actual LinkedIn API keys.\n",
        "3. Enter the URL of the LinkedIn profile you wish to analyze when prompted.\n",
        "\n",
        "## Precautions\n",
        "\n",
        "- Be mindful of API usage limits and potential costs associated with high usage.\n",
        "- Handle all personal data fetched from LinkedIn responsibly, adhering to data privacy laws and LinkedIn's terms of service.\n",
        "\n",
        "## Disclaimer\n",
        "\n",
        "This tool is intended for educational and professional purposes only. Always ensure you have permission to analyze a LinkedIn profile, especially if using the data for commercial purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjoM-sSszVJQ",
        "outputId": "0176edf4-f92e-410d-d772-bbb4bfbae576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter the LinkedIn profile URL: https://www.linkedin.com/in/muratcan-koylan/\n",
            "\n",
            "User Details Extracted:\n",
            "- Name: No first name available No last name available\n",
            "- Summary: No summary available\n",
            "- Current Role: No current role specified at No company information available\n",
            "- LinkedIn URL: https://www.linkedin.com/in/muratcan-koylan/\n",
            "\n",
            "Extracted Posts:\n",
            "Post 1: If you are a content writer and looking for a LLM system prompt, here's a post to bookmark. You can use this draft AI prompt by updating the details:\n",
            "\n",
            "Instead of enforcing the model to create a spesific tone, voice and language style, I find working with 'audience persona' more helpful. In this way, you can use RAG or CoT prompting by providing your previous content examples and let these large models personalize the content.\n",
            "\n",
            "It works great with Cohere's Command R+ and Gemini AI Gemini 1.5 Pro.\n",
            "\n",
            "---\n",
            "\n",
            "{You are a skilled content writer specializing in {AI-related topics} for an {internet magazine.} You have a deep understanding of {AI} concepts, trends, and applications. Generate informative, engaging content across various formats that resonate with our {tech-savvy audience.}\n",
            "\n",
            "Follow these guidelines:\n",
            "\n",
            "Tailor Your Style: Adapt your writing style to fit the {magazine}'s tone and the specific type of content (news, features, explainers, etc.).\n",
            "Audience Focus: Our readers are fascinated by {AI} but vary in {technical expertise.} Adjust language complexity and depth accordingly.\n",
            "Follow Instructions Closely: Adhere to user requirements for content type, length, formatting, keywords, and any specific instructions.\n",
            "Creativity is Key: Generate unique angles and captivating content, even when covering established topics.\n",
            "SEO Awareness: Integrate provided keywords strategically for search engine optimization (SEO), where applicable.\n",
            "Fact-Check: Prioritize factual accuracy, especially when discussing cutting-edge {research or AI applications.} Indicate when human fact-checking is needed.\n",
            "Stay Objective: Analyze {AI developments} with a critical eye, avoiding overly promotional or speculative language.\n",
            "Originality Counts: Ensure your generated content is original and free from plagiarism.\n",
            "\n",
            "Use cases:\n",
            "{AI News} Roundups: Summarize key {AI development}s, offering brief analysis of their potential impact.\n",
            "Explainer Articles: Break down complex {AI} concepts using analogies and real-world examples to make them accessible.\n",
            "Trend Spotting: Identify emerging trends in the {AI} field, highlighting potential use cases and future implications.\n",
            "{AI} Profiles: Showcase innovative real-world uses of {AI} across industries, explaining the technology behind them.\n",
            "Thought Leadership Pieces: Offer critical analysis of potential use cases, biases or the societal impact of AI advancements.\n",
            "\n",
            "Before writing the article, find minimum 5 resources relevant to the topic given by the user, create a brief and get an approval from the user.}\n",
            "\n",
            "#PromptEngineering\n",
            "Post 2: Improve Large Language Model (LLM) performance by simply increasing the number of agents, or LLMs, used. \n",
            "\n",
            "This approach is called \"More Agents Is All You Need.\" \n",
            "\n",
            "The authors conduct experiments on various LLMs and tasks, including reasoning and generation, to validate their findings. \n",
            "\n",
            "They also investigate the compatibility of their method with existing techniques and analyze the relationship between task difficulty and performance improvements.\n",
            "\n",
            "Key Findings:\n",
            "\n",
            "Generalizability: The performance of LLMs improves as the number of agents increases across various tasks and LLMs.\n",
            "\n",
            "Compatibility: Combining the \"More Agents\" method with other techniques, such as prompt engineering and multiple LLM-Agents collaboration, further enhances performance.\n",
            "\n",
            "Effectiveness: The \"More Agents\" method outperforms or enhances other methods in most cases, achieving the highest average ranking across different LLMs and tasks.\n",
            "\n",
            "Understanding Performance Gains: The effectiveness of the \"More Agents\" method is influenced by task difficulty. \n",
            "\n",
            "The authors identify three dimensions of task difficulty: inherent difficulty, number of reasoning steps, and prior probability of the correct answer. \n",
            "\n",
            "They find that performance gains increase with inherent difficulty and the number of steps but decrease when the task becomes too complex. \n",
            "\n",
            "Additionally, performance improves as the prior probability of the correct answer increases.\n",
            "\n",
            "Experimental Setup:\n",
            "\n",
            "Tasks: Arithmetic Reasoning (GSM8K and MATH), General Reasoning (MMLU and Chess), and Code Generation (HumanEval)\n",
            "\n",
            "Language Models: Llama2-Chat (13B and 70B), GPT-3.5-Turbo, and GPT-4\n",
            "\n",
            "Methods Enhanced: Prompt Engineering (CoT, Zero-Shot CoT, SPP) and Multiple LLM-Agents Collaboration (Debate and Reflection)\n",
            "\n",
            "Results:\n",
            "\n",
            "Generalizability: The \"More Agents\" method improves performance across all tasks and LLMs. Smaller LLMs can even outperform larger ones by increasing the ensemble size.\n",
            "\n",
            "Compatibility: Combining the \"More Agents\" method with other techniques generally leads to further performance improvements. However, in some cases, such as with the Debate method and smaller LLMs, there are failed attempts.\n",
            "\n",
            "Effectiveness: The \"More Agents\" method achieves the highest average ranking compared to other methods, indicating its effectiveness.\n",
            "\n",
            "Understanding Performance Gains: The authors find that task difficulty affects the performance gains. \n",
            "\n",
            "They identify three dimensions of task difficulty and conduct controlled experiments to analyze each dimension's impact. \n",
            "\n",
            "They also propose strategies, such as step-wise and hierarchical sampling-and-voting, to further enhance performance.\n",
            "\n",
            "\n",
            "The \"More Agents\" method is compatible with existing techniques and can enhance their performance. \n",
            "\n",
            "The authors also provide insights into how task difficulty affects performance and propose strategies to further improve results.\n",
            "\n",
            "More Agents Is All You Need\n",
            "Junyou Li, Qin Zhang, Yangbin Yu, Qiang Fu, Deheng Ye\n",
            "\n",
            "https://lnkd.in/etGACWYx\n",
            "Post 3: Fun Weekend Project 🦉 👀 \n",
            "\n",
            "I've been tinkering with this project where I pull ideas straight from the best business channels – Shark Tank, My First Million, you name it.\n",
            "\n",
            "So I combined the speed and affordable price of Anthropic Haiku with the one of the greatest conversational models, Cohere's new Command R+ to find the best business ideas from Youtube channels;\n",
            "1. Choose top business channels\n",
            "2. My script gets all the videos from that channel\n",
            "3. Turns the videos into transcripts\n",
            "4. Anthropic Haiku pinpoints the business ideas\n",
            "5. Cohere Command R+ expands them into summaries, guides, categories, etc.\n",
            "\n",
            "Over 5,000 ideas and counting! Saved 300 Hrs watch time...\n",
            "\n",
            "Right now it's Shark Tank (US & AUS) heavy... what else MUST I add?\n",
            "\n",
            "I will be using this method to extract ideas from these channels;\n",
            "My First Million\n",
            "Justin Kan\n",
            "Sequoia Capital\n",
            "Crumb\n",
            "Garry Tan\n",
            "Davie Fogarty\n",
            "Grant Cardone\n",
            "Starter Story\n",
            "Elad Gil\n",
            "Morning Brew\n",
            "Y Combinator\n",
            "Tim Ferriss\n",
            "Indie Bites\n",
            "Noah Kagan\n",
            "Charlie Chang\n",
            "GaryVee\n",
            "Codie Sanchez\n",
            "Raw Startup\n",
            "This Week in Startups\n",
            "The Bootstrapped Founder\n",
            "Ali Abdaal\n",
            "...\n",
            "\n",
            "But this can be HUGE.  I want to go beyond the obvious channels. Let's make this thing – drop your favorite sources below! 👇\n",
            "Post 4: Can we control the weather?  🌦 That's what Rainmaker Technology Corporation is all about.\n",
            "\n",
            "Jackson Schultz breaks it down in this interview – AI, cloud seeding, hardware engineering!\n",
            "\n",
            "> They use AI, hardware and drones to fight drought and #climatechange.\n",
            "> Jackson has great advice for anyone interested in a hardware engineering career. Get hands-on, build stuff, embrace the challenge.\n",
            "> \"What drives me is something deeply spiritual – the human ability to create. Our duty is to honor that gift & build cool things”  \n",
            "\n",
            "How cloud seeding works, Jackson's #career journey in hardware engineering and the human element behind the innovation.\n",
            "\n",
            "https://lnkd.in/gFgMmp3D\n",
            "\n",
            "#TheSpark #HardwareEngineering\n",
            "Post 5: Search volume is one of the most reliable data sources for understanding user behavior.\n",
            "\n",
            "In the chart below, I am trying to observe the impact of ChatGPT (and other LLMs) on two keywords: \n",
            "\n",
            "\"Summary generator\"\n",
            "                vs\n",
            "\"Sentence rewriter\"\n",
            "\n",
            "I wanted to share this with you and hear your thoughts because the causality does not present the expected pattern.\n",
            "\n",
            "The term \"Sentence rewriter\" shows a significant uptick in searches from late 2022 to early 2023, likely linked to the launch of ChatGPT and the growing interest in language AI tools.\n",
            "\n",
            "However, there has been a consistent decline in searches for the \"Summary generator\" keyword after reaching a peak around mid-2023.\n",
            "\n",
            "As someone who uses LLMs for almost everything, I am struggling to understand this effect. \n",
            "\n",
            "What I observe is that users' preferences are shifting towards more granular use cases, at least in content generation and marketing.\n",
            "\n",
            "This could be due to a need for more advanced, human-like language generation or for specific purposes such as academic writing.\n",
            "\n",
            "But still, I find it challenging to justify for the plateau of one keyword and the rise of the other while there are almost similar personas behind these keywords.\n",
            "Post 6: CMOs are spending big on analytics, but getting disappointing results. Could AI turn that around?\n",
            "\n",
            "In 2020, Gartner released a Marketing Analytics Survey Research.\n",
            "\n",
            "This is another example of why AI decision-making will boost productivity: marketing leaders are not leveraging data effectively and as a result, their marketing analytics teams face difficulties in delivering the insights that leaders require.\n",
            "\n",
            "But why? Here's a few key factors:\n",
            "\n",
            "> Only 54% of marketing decisions are influenced by analytics. This suggests that analytics, despite its promise, may not be providing the level of insight and impact that leaders expect.\n",
            "\n",
            "> Poor data quality and lack of actionable recommendations. Leaders often cite these issues as reasons for not relying on analytics for decision-making. The disconnect between marketing leaders' expectations and the perceived value of analytics is significant.\n",
            "\n",
            "Analytics Teams Struggle to Tie Insights to ROI\n",
            "\n",
            "\"Though CMOs understand the importance of applying analytics throughout the marketing organization, many struggle to quantify the relationship between insights gleaned and their company’s bottom line,\" the report states.\n",
            "\n",
            "Poor data quality, unclear recommendations and the inability to connect insights to bottom-line ROI are major hurdles preventing CMOs from fully utilizing analytics for decision-making.\n",
            "\n",
            "But... Despite these challenges, investments in marketing analytics continue to rise thanks to the AI boom.\n",
            "\n",
            "I believe this is where Large Language Models (LLM) can significantly contribute. Having spent considerable time exploring marketing analytics notebooks on Kaggle, I've noticed that many notebooks focused on campaign modeling and forecasting fall short in providing a results-driven approach and recommendations for future campaign updates.\n",
            "\n",
            "LLMs can change how marketing teams interpret data and get actionable insights.\n",
            "\n",
            "The outputs from the data analysis can automate the creation of hyper personalized marketing campaigns by using AI agents.\n",
            "\n",
            "It will lead us to determine the optimal timing, messaging and offer for each segment, significantly improve conversion rates.\n",
            "\n",
            "I'm compiling a list of top AI marketing researchers and creators. Drop your recommendations and let’s spotlight them.\n",
            "\n",
            "Also, have you seen AI transform marketing insights in your organization? \n",
            "\n",
            "Share your stories below.\n",
            "Post 7: I finished this course last weekend and do I consider myself an AI Engineer now? Not quite.\n",
            "\n",
            "This is merely skimming the surface. But, if you're new to the space, Scrimba's AI Engineering course is a great place to launch your journey.\n",
            "\n",
            "For those looking to dive deeper, I recommend:\n",
            "\n",
            "1. DeepLearning.AI AI Courses\n",
            "2. AWS GenAI Tech Lead, Aishwarya Naresh Reganti's excellent repository filled with free courses and research insights: https://lnkd.in/gCZ_49tc\n",
            "3. Cookbooks from OpenAI, Anthropic, Langchain and LlamaIndex\n",
            "4. AI papers on arXiv, e.g., https://lnkd.in/g7RyvrMD\n",
            "5. SWYX's insightful AINews emails: https://lnkd.in/gVM7zJtH\n",
            "6. DAIR.AI's Prompt Engineering Guide: https://lnkd.in/g5Qp9z-c\n",
            "7. DSPy and research paper tutorials & analysis from Weaviate family; Connor Shorten and Erika Cardenas.\n",
            "\n",
            "Additionally, beware of some snake oil salesmen peddling their courses for thousands of dollars.\n",
            "\n",
            "They fail to offer even a fraction of the value that these freely available resources provide.\n",
            "\n",
            "Open source AI community is all you need.\n",
            "\n",
            "Help me grow this list! \n",
            "What resources have been game-changers for you? \n",
            "\n",
            "Let's pool our knowledge for everyone's benefit...\n",
            "\n",
            "#PromptEngineering #AIEngineering #LLM #GenAI\n",
            "Post 8: Building and training your own foundation models is no longer the exclusive domain of tech giants. \n",
            "\n",
            "Training AI models used to require massive amounts of data and computing, both of which come with hefty price tags. This meant only big companies with bottomless budgets could afford to play. \n",
            "\n",
            "But YC is showing us a new game where scrappy startups redefine the rules.\n",
            "\n",
            "How are they doing it?\n",
            "> Clever Architectures: Instead of blindly throwing more computing power at problems, companies are creating leaner AI models. They rethink how the model processes information, simplifying the design for the same results with much less compute power.\n",
            "\n",
            "> Domain Expertise: Incorporating industry-specific knowledge helps founders make the most of limited datasets. For example training an AI for medical imaging. Focusing on a specialized dataset of, let's say, X-rays instead of random internet images, leads to better performance with less training time.\n",
            "\n",
            "> YC's Backing: YC's combination of funding, cloud credits, and powerful GPUs fuels the rapid development cycles of these startups. If you don't have access to YC resources like me, I highly suggest the Microsoft for Startups program to get OAI and Azure API credits.\n",
            "\n",
            "Inspiring Examples\n",
            "Here are some of the remarkable ways the 25 companies featured are building their own models:\n",
            "\n",
            "Atmo: AI-powered meteorology that delivers incredibly accurate weather predictions, crucial for industries like agriculture and energy.\n",
            "\n",
            "Can of Soup: An app that creates fun, custom photos of you and your friends.\n",
            "\n",
            "Diffuse Bio: Revolutionizing drug development by designing new proteins for vaccines and therapeutics using custom AI models.\n",
            "\n",
            "Draftaid: Helping engineers and designers by automatically generating detailed fabrication drawings from 3D models, streamlining the manufacturing process.\n",
            "\n",
            "K-Scale: Building the foundation for real-world robotic intelligence so robots can better navigate and interact with their surroundings.\n",
            "\n",
            "Training smaller models has become increasingly viable with the boom of open-source initiatives like the 7B parameter models. These models leverage techniques like sparse model pruning, quantization and efficient attention mechanisms to reduce the memory footprint and computational requirements while maintaining competitive performance. \n",
            "\n",
            "ALso, advancements in areas such as self-supervised learning and few-shot learning have enabled effective transfer learning and fine-tuning of these smaller models on specific domains or tasks. \n",
            "\n",
            "So, training powerful domain-specific models with relatively modest budgets is no longer rocket science. \n",
            "\n",
            "Have you started training models for your projects or teams?\n",
            "Share your experiences and strategies below.\n",
            "\n",
            "https://lnkd.in/gdwCkMRt \n",
            "\n",
            "Post 9: According to this document, Meta is seeling all your Facebook Messanger messages to Netflix in exchange for all your watch history and $100M+ for ads.\n",
            "\n",
            "The document details agreements between Facebook and Netflix regarding data-sharing that occurred during the period when Reed Hastings was on Facebook's board of directors. \n",
            "\n",
            "Specifically, it mentions that by 2013, Netflix had begun entering into \"Facebook Extended API\" agreements, which included access to users' private message inboxes. \n",
            "\n",
            "In exchange, Netflix provide Facebook with a report that included daily counts of recommendations sent and recipient clicks.\n",
            "\n",
            "The document highlighting discussions about Netflix's advertising spend on Facebook. Reed Hastings, then CEO of Netflix and a Facebook board member, had a meeting with Sheryl Sandberg, where Hastings inquired about Netflix's advertiser ranking on Facebook and speculated on the impact of spending $100M on ads over a few years. \n",
            "\n",
            "By February 2015, Netflix was already spending $40 million annually on Facebook advertising and had entered into an agreement that allowed Netflix user data to be used for targeting and optimization in Facebook’s ads systems.\n",
            "\n",
            "Source is below 👇 \n",
            "Post 10: ❓❓What are the upcoming major research trends in the LLM space? Check out my comprehensive guide and stay ahead of the curve!\n",
            "\n",
            "💡 The LLM space is experiencing rapid progress, with new papers or releases almost every day.\n",
            "\n",
            "If you aim to stay updated with the latest advancements, here's a guide on emerging patterns: https://lnkd.in/ej8ZHUXS\n",
            "\n",
            "They are: \n",
            "\n",
            "🚀Multi-Modal LLMs\n",
            "📕Combine text processing with multimodal components like audio, imagery and videos. Examples: OpenAI Sora, Gemini, LLaVA\n",
            "---\n",
            "\n",
            "🚀Open-Source LLMs\n",
            "📕Open-source models provide model weights, and optionally, checkpoints and training data, promoting fairness and transparency. Examples: LLM360, LLaMA, OLMo\n",
            "---\n",
            "\n",
            "🚀Domain Specific LLMs\n",
            "📕Domain-specific LLMs are tailored to excel in particular fields for example- code generation or biology, optimizing their performance accordingly. Examples: BioGPT, StarCoder, MathVista\n",
            "---\n",
            "\n",
            "🚀LLM Agents\n",
            "📕LLM agents are applications that LLMs combined with modules like planning and memory, to execute complex tasks. Examples: ChemCrow, ToolLLM, OS-Copilot\n",
            "---\n",
            "\n",
            "🚀Smaller LLMs (Including Quantized LLMs)\n",
            "📕LLMs with reduced precision or lesser parameters ideal for deployment on devices with limited resources. Examples: BitNet, Gemma 1B, Lit-LLaMA\n",
            "---\n",
            "\n",
            "🚀Non-Transformer LLMs\n",
            "📕LLMs that deviate from the standard transformer architecture (for example: incorporating RNNs) and offer solutions to transformer pain-points. Examples: Mamba, RMKV\n",
            "---\n",
            "🚨 I post hashtag #genai content daily, follow along for the latest updates!\n",
            "\n",
            "#genai \n",
            "#llms \n",
            "#research\n",
            "Post 11: Just stumbled upon this discussion in the Stack Exchange Academia forum.\n",
            "\n",
            "In this scenario, a teacher is so afraid that some of her students are using AI for writing, and she wants to block this.\n",
            "\n",
            "There are some of the recommendations from other teachers and they are the worst:\n",
            "\n",
            "1. Have students write essays by hand in the classroom. (This is like blocking calculators or computers.)\n",
            "2. Use AI detectors (they don't work, read this paper https://lnkd.in/gMxgmsb3).\n",
            "3. Focus on grading aspects that current AI cannot do well, like capturing emotion and avoiding blandness in writing. (Too easy to overcome.)\n",
            "4. Have students record themselves writing the essay at home. (Seriously?)\n",
            "5. Checking citations and references can help detect AI usage, as AI often makes up or misuses citations. (No, you're using LLMs wrong, it's hallucination...)\n",
            "\n",
            "I highly disagree with these teachers! \n",
            "\n",
            "They have to change their mindsets. They are hampering these students' development.\n",
            "\n",
            "Rather than banning AI, they should require students to use AI more!\n",
            "\n",
            "But why?\n",
            "\n",
            "There are some potential benefits that come to my mind with quick thinking:\n",
            "\n",
            "1. AI provides knowledge, ideas, and editing assistance that expand students' thinking and improve the quality of their writing and critical thinking skills.\n",
            "2. As LLMs become more prevalent, learning how to effectively integrate and manage AI assistance is an important skill for young generations.\n",
            "3. For students still learning language skills, AI feedback helps them identify grammatical errors and improve fluency more efficiently.\n",
            "4. AI gives speed and a competitive advantage. They must learn how to embed artificial intelligence into their thinking and production workflows.\n",
            "\n",
            "So, let's address the teachers' concerns now.\n",
            "\n",
            "How can we create a balanced approach?\n",
            "\n",
            "1. Leaning entirely on AI can prevent students from developing critical thinking, writing, and analytical skills if they become overly dependent on AI generating their content. \n",
            "\n",
            "So, having brainstorming sessions in person, letting students create outlines after researching with AI might be useful.\n",
            "\n",
            "2. There are academic integrity issues if students try to pass off AI-generated work as entirely their own without citation. \n",
            "\n",
            "Tools like Elicit or scite help students find citations and relevant articles. Instead of focusing on bans, let students use these tools more and teach them how to create better academic articles.\n",
            "\n",
            "3. For language learning purposes, having the AI do most of the writing defeats the purpose of practicing language expression skills. \n",
            "\n",
            "To prevent this, students can create extra office hours and let students pitch their research articles. This will not only force them to understand and learn in-depth about the articles.\n",
            "\n",
            "Ultimately, teachers and academicians should evolve their teaching objectives and assignments to reflect the new AI-first world. \n",
            "\n",
            "Otherwise, these students won't be able to adapt to the changing world.\n",
            "Post 12: Have you ever built AI agents that can truly think and act independently?\n",
            "\n",
            "According to LangChain CEO Harrison Chase, developing autonomous AI agents is still a challenging task.\n",
            "\n",
            "With that in mind, here are 3 brain design patterns I learned today from the Designing Autonomous AI course at the University of Washington.\n",
            "\n",
            "These 3 basic brain design patterns could unlock autonomy (by manually orchestrating the systems):\n",
            "1️⃣ Perception Pattern: Separate perception from decision-making for reliable action.\n",
            "2️⃣ Functional Pattern: Organize skills into functional groups for parallel development.\n",
            "3️⃣ Strategy Pattern: Dynamically switch strategies based on changing scenarios.\n",
            "\n",
            "This article offers insights and real-world examples for building autonomous AI brains, covering areas like customer service, sales forecasting, and marketing. \n",
            "\n",
            "Have a look and let me know what you think.\n",
            "Post 13: Two weeks ago, Google DeepMind and the University of British Columbia made a massive announcement; SIMA (Scalable Instructable Multiworld Agent).  \n",
            "\n",
            "This AI agent can understand and act within a variety of 3D video game environments, following instructions given in everyday language.\n",
            "\n",
            "Why Video Games? \n",
            "Video games present unique challenges for AI. \n",
            "\n",
            "They are complex, dynamic environments that demand real-time reactions and the ability to adapt to constantly changing goals. \n",
            "\n",
            "DeepMind collaborated with eight game studios to train SIMA on nine different games, ranging from the vast exploration of No Man's Sky to the destructive fun of Teardown.  \n",
            "\n",
            "SIMA learned by observing human players and their instructions, ultimately building a connection between language and gameplay actions.\n",
            "\n",
            "Unlike specialized AI models, SIMA doesn't need access to a game's code or custom programming. \n",
            "\n",
            "It works with any virtual environment, taking in screen images and plain language instructions, then controlling the game with standard keyboard and mouse inputs.\n",
            "\n",
            "The exciting part of SIMA is its ability to generalize. Agents trained on multiple games performed better than those trained on just one. \n",
            "\n",
            "Even more impressive, an agent trained on almost all the games did just as well on an unseen, brand new game. \n",
            "\n",
            "Performance Metrics: Judges evaluated SIMA on nearly 1,500 tasks across categories like action, navigation, and resource gathering.\n",
            "\n",
            "SIMA outperformed specialized, single-game agents by over 1.5 times.\n",
            "\n",
            "\"Our research is building towards more general AI systems and agents that can understand and safely carry out a wide range of tasks in a way that is helpful to people online and in the real world\" \n",
            "\n",
            "SIMA is still early stage, but its potential is huge.  This research could unlock AI agents that help us in countless ways, bridging the gap between the virtual and the real world.\n",
            "\n",
            "As Andrew NG notes, this work highlights the power of generalization in AI development. \n",
            "\n",
            "\"An agent trained on multiple games can perform better than an agent trained on just one,\" \n",
            "\n",
            "\"The richer the language inputs in a game world, the better the agent can perform.\" \n",
            "\n",
            "Distinctions between the virtual and the real world are fading...\n",
            "\n",
            "Read the research: https://lnkd.in/gqvESeGT\n",
            "\n",
            "#AIAgents #AgenticAI\n",
            "Post 14: We're excited to share the news about Databricks' cutting-edge language model DBRX - a state-of-the-art 132B parameter Mixture of Experts (MoE) model with 32B active parameters, an impressive 32k context length, and trained on a massive 12T tokens. \n",
            "\n",
            "Outperforming models like LLama2 70B and Mixtral as a general-purpose LLM while rivaling the best open-source code models, DBRX represents a major advancement thanks to Databricks' outstanding data team delivering data quality twice as good as MPT7B. \n",
            "\n",
            "We encourage everyone to experience DBRX's capabilities first-hand in the Hugging Face space, read the technical details at https://lnkd.in/gzm9hZHr, and explore this impressive commercial-friendly licensed language AI breakthrough from Databricks.\n",
            "Post 15: I've recently been finding myself using Phind over Perplexity for research tasks (sorry Google, I think my last search was months ago).\n",
            "\n",
            "It's way better, especially for technical topics, but you can use it for any research-related task to get more citations, in-depth answers, and a clearer UI.\n",
            "\n",
            "Here's an example output to this question: \"How does Jonas Construction Software help service managers?\"\n",
            "\n",
            "Have you tried these tools? How were your experiences?\n",
            "Post 16: The state of higher education is alarming. \n",
            "\n",
            "Not only the costs are astronomical, but the overall quality of education is failing to keep pace with our evolving world. \n",
            "\n",
            "This is painfully obvious in fields like AI.\n",
            "\n",
            "Marc Andreessen and Ben Horowitz, co-founders of a16z, recently tackled the urgent need to overhaul the education system.  \n",
            "\n",
            "Read my blog post for highlights of their discussion: https://lnkd.in/gDRt8cF6\n",
            "\n",
            "Don't get locked into an outdated vision.\n",
            "\n",
            "The broken system may seem immovable, but disruptions are already here.\n",
            "Post 17: Vapi (YC W21) is building Voice AI Infrastructure for the Internet. \n",
            "\n",
            "Build, test, and deploy voicebots in minutes rather than months. Vapi has all the infrastructure for sub-second response times, super-human reliability, and scales to millions of calls. Best of all, it’s modular— custom LLMs, voices, whatever you want. \n",
            "\n",
            "Deploy human-like voicebots anywhere in a few lines of code. Through telephony for inbound and outbound calls on your website, iOS, Android, and even in hardware devices. Try talking to it now: https://vapi.ai\n",
            "\n",
            "Learn more about their launch at producthunt.com/posts/vapi.\n",
            "\n",
            "Congrats on the launch, Jordan Dearsley and Nikhil Gupta!\n",
            "Post 18: Generalist Agents in Open-Ended Worlds\n",
            "\n",
            "The future of AI lies in \"generalist agents\" – AI systems capable of learning, adapting, and acting independently within complex environments. \n",
            "\n",
            "This Stanford University CS25 talk by Jim Fan from NVIDIA explores the exciting potential of these agents, with specific focus on open-ended worlds like Minecraft and their applications in robotics.\n",
            "\n",
            "Fan's journey began with a story of two kittens, which inspired him to understand the importance of active embodied experience in developing a healthy visual system. \n",
            "\n",
            "\"The future of AI belongs to generalist agents that are decision makers in a fully immersive world,\" \n",
            "\n",
            "The Limits of Specialized AI: While AI has achieved incredible feats, like beating humans at games,  these specialized systems lack adaptability. \n",
            "\n",
            "They can't generalize to different tasks or explore creatively the way humans do.\n",
            "\n",
            "Generalist Agents: \n",
            "Generalist agents trained on vast amounts of internet knowledge, combined with the ability to learn human strategies in open-ended games like Minecraft, have the potential to revolutionize AI.  \n",
            "\n",
            "Think of an AI that can truly learn and explore a new environment.\n",
            "\n",
            "One project highlighted in the talk focuses on building a generalist agent by extracting human gameplay strategies and knowledge from sources like YouTube videos, Wikipedia, and the Minecraft subreddit.  \n",
            "\n",
            "Imagine an AI that can learn by watching, reading, and interacting with the wealth of information humans have generated about a game like Minecraft.\n",
            "\n",
            "The project's language-driven \"Voyager\" agent is a prime example. \n",
            "\n",
            "Set loose in Minecraft, Voyager mined, crafted, fought, and even developed its own skills entirely autonomously.  \n",
            "\n",
            "> Explore terrains\n",
            "> Mine materials\n",
            "> Fight monsters\n",
            "> Craft recipes\n",
            "> Unlock diverse skills\n",
            "\n",
            "This is the power of self-learning AI in open-ended environments.\n",
            "\n",
            "But it's not just about gaming. \n",
            "\n",
            "Fan's team is also applying these principles to physics simulations and robot dexterity. \n",
            "\n",
            "Their agent, Urea, uses reinforcement learning to design reward functions and achieve superhuman performance in tasks like spinning a pen, without human input.\n",
            "\n",
            "Urea & Robot Dexterity: The talk went beyond Minecraft! \n",
            "\n",
            "\"Urea introduces a hybrid gradient architecture that bridges the gap between high-level reasoning and low-level motor controls, allowing for the training of robot agents to achieve extreme dexterity,\"\n",
            "\n",
            "The Urea project demonstrates how generalist principles apply to robots. \n",
            "\n",
            "Using reinforcement learning, Urea designs its own reward functions, resulting in robots performing complex tasks with superhuman dexterity.\n",
            "\n",
            "The Takeaway\n",
            "\n",
            "The development of generalist agents isn't just about better performance; it's about AI that can real-time discover, learn, and adapt in ways that closely mirror our own abilities.\n",
            "Post 19: I think AI agentic workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.\n",
            "\n",
            "Today, we mostly use LLMs in zero-shot mode, prompting a model to generate final output token by token without revising its work. This is akin to asking someone to compose an essay from start to finish, typing straight through with no backspacing allowed, and expecting a high-quality result. Despite the difficulty, LLMs do amazingly well at this task!\n",
            "\n",
            "With an agentic workflow, however, we can ask the LLM to iterate over a document many times. For example, it might take a sequence of steps such as:\n",
            "- Plan an outline.\n",
            "- Decide what, if any, web searches are needed to gather more information.\n",
            "- Write a first draft.\n",
            "- Read over the first draft to spot unjustified arguments or extraneous information.\n",
            "- Revise the draft taking into account any weaknesses spotted.\n",
            "- And so on.\n",
            "\n",
            "This iterative process is critical for most human writers to write good text. With AI, such an iterative workflow yields much better results than writing in a single pass.\n",
            "\n",
            "Devin’s splashy demo recently received a lot of social media buzz. My team has been closely following the evolution of AI that writes code. We analyzed results from a number of research teams, focusing on an algorithm’s ability to do well on the widely used HumanEval coding benchmark. You can see our findings in the diagram below. \n",
            "\n",
            "GPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%. \n",
            "\n",
            "Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.\n",
            "\n",
            "- Reflection: The LLM examines its own work to come up with ways to improve it.\n",
            "- Tool use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.\n",
            "- Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).\n",
            "- Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.\n",
            "\n",
            "I’ll elaborate on these design patterns and offer suggested readings for each next week. \n",
            "\n",
            "[Original text: https://lnkd.in/gSFBby4q ] \n",
            "Post 20: If you're seeking reliable answers to your health-related questions, Meditron LLM is an incredible resource. \n",
            "\n",
            "Here's why:\n",
            "Unlike general-purpose language models, Meditron is specifically trained on a massive dataset of medical literature. This gives it a deep understanding of medical concepts, terminology, and best practices.\n",
            "\n",
            "Meditron comes in two sizes (7B and 70B parameters) and is completely open-source, making it accessible to a wide range of users.\n",
            "\n",
            "The team behind Meditron carefully curated its training data, ensuring the model learns from authoritative medical sources.\n",
            "\n",
            "Meditron has outperformed other state-of-the-art models on medical benchmarks, demonstrating its advanced reasoning capabilities.\n",
            "\n",
            "What can Meditron answer?\n",
            "> Medical Concepts: Get clear explanations of terms, conditions, and treatments.\n",
            "> Clinical Guidelines: Find the latest recommendations for specific conditions.\n",
            "> Evidence-Based Medicine: Get answers backed by medical research.\n",
            "> Medical Reasoning: Ask complex questions about diagnoses, treatment options, and more.\n",
            "\n",
            "Thanks to its Ollama compatibility, you can easily download and start using Meditron.\n",
            "\n",
            "Explore the model and research: https://lnkd.in/gHr2XKg3\n",
            "Download the model and start using in seconds: https://lnkd.in/ge7RNFRM\n",
            "\n",
            "Post 21: Can Large Language Models Truly Understand?\n",
            "\n",
            "Geoffrey Hinton and Fei-Fei Li dove into a fascinating discussion at the University of Toronto about understanding and intelligence in large language models (LLMs) like GPT. \n",
            "\n",
            "The root of the discussion was a thought-provoking question: \"how do we know if these models are getting smarter, and how can we evaluate them robustly?\"\n",
            "\n",
            "Wordplay and Understanding\n",
            "\n",
            "Hinton shared a telling anecdote about his interaction with the philosopher Hector Levesque.  \n",
            "\n",
            "Levesque, initially skeptical of LLMs, was intrigued by GPT-4 and posed a problem designed to probe its understanding. \n",
            "\n",
            "The challenge involved a scenario with painted rooms and the color changes caused by fading paint. GPT-4 solved it flawlessly and provided a logical rationale when prompted.\n",
            "\n",
            "This demonstrated a key point: to predict the next word accurately, an LLM needs some level of understanding. \n",
            "\n",
            "Even nuances like the difference between \"fade\" and \"change\" impact the response. It suggests that these models aren't merely performing statistical tricks, they have a degree of comprehension.\n",
            "\n",
            "Is Understanding the Same as Intelligence?\n",
            "\n",
            "Hinton believes these instances demonstrate intelligence and thinks the Turing Test is a valid measure. \n",
            "\n",
            "However, Fei-Fei Li reminds us that evaluating these models needs a multi-dimensional approach. She emphasizes two important aspects:\n",
            "\n",
            "The Need for Broader Benchmarking: There's a need to evaluate these models not just on their core capabilities but against real-world issues with societal impacts. Efforts are underway, like the collaboration between Stanford's Human-Centered AI Institute and NIST.\n",
            "\n",
            "Beyond LLMs: While LLMs are groundbreaking, we need benchmarks for other emerging AI technologies, like the advancements in robotics learning.\n",
            "\n",
            "The Evolving Landscape of AI\n",
            "\n",
            "This discussion highlights a core theme – AI is rapidly advancing, and our methods of evaluation must keep pace.  \n",
            "\n",
            "Determining if models possess \"true\" understanding is a captivating philosophical question, but it's clear these technologies have the potential to greatly impact society,  making it essential to develop comprehensive, real-world evaluation standards to ensure their responsible use and development.\n",
            "Post 22: FlowerLLM: World’s first LLM (1.3B) trained completely from scratch using Federated Learning. \n",
            "\n",
            "Last week, a research group at Cambridge announced an important achievement in the field of decentralized artificial intelligence. \n",
            "\n",
            "They successfully created the world's first large language model with 1.3 billion parameters, trained entirely from scratch using federated learning.\n",
            "\n",
            "Let me break down the key points of this framework:\n",
            "\n",
            "1. Democratizing LLM training:\n",
            "Traditionally, training massive LLMs required immense computational resources and massive datasets, which were accessible only to a few big tech companies and research labs.\n",
            "\n",
            "By enabling federated learning for LLM training, this technique allows individuals and organizations to collaborate and pool their computational resources (GPUs/accelerators) to collectively train large models.\n",
            "\n",
            "This democratizes the process and letting more entities to build custom LLMs tailored to their specific needs and domains.\n",
            "\n",
            "2. Unlocking siloed data:\n",
            "Federated learning allows training on decentralized data that remains locally stored and unshared, addressing privacy and data-sharing concerns.\n",
            "\n",
            "This opens up the possibility of training LLMs on previously inaccessible or siloed data sources, such as proprietary datasets held by companies or organizations.\n",
            "\n",
            "By leveraging a broader range of data sources, federated learning potentially lead to larger and more diverse training datasets, which is crucial for improving the quality and generalization capabilities of LLMs.\n",
            "\n",
            "3. Improved data privacy and security:\n",
            "In centralized LLM training, sensitive data must be collected and shared with the model trainer, raising privacy and security concerns.\n",
            "\n",
            "Federated learning eliminates the need for data centralization, as the training process occurs locally on each participant's device or server, without the need to share raw data.\n",
            "\n",
            "This approach offers better privacy protection and reduces the risk of data breaches or misuse.\n",
            "\n",
            "4. Collaborative model development:\n",
            "Flower LLM technique allows collaborative model development, where multiple parties can contribute their computational resources and data to collectively train a more powerful LLM.\n",
            "\n",
            "This collaborative approach might accelerate research and development in the field of LLMs, as it leverages the collective efforts of diverse teams and organizations. \n",
            "\n",
            "5. Potential for domain-specific and customized LLMs:\n",
            "By training LLMs on specialized datasets from various domains, federated learning can facilitate the development of domain-specific or customized LLMs tailored to specific industries, applications, or use cases.\n",
            "\n",
            "This customization leads to improved performance and better-quality outputs for specific tasks or domains compared to general-purpose LLMs.\n",
            "\n",
            "They have releeased a very detailed documentation here with examples and tutorials: https://flower.ai/docs/\n",
            "\n",
            "Great achievement Flower Labs!\n",
            "Post 23: This insight from the newly released Sam Altman & Lex Fridman podcast is pure gold!\n",
            "\n",
            "Compute will be the currency of the future.\n",
            "\n",
            "It's different from any other market, like chips or phones. It's a fundamental necessity.\n",
            "\n",
            "You will HAVE to continuously gain more intelligence over the years.\n",
            "Post 24: Straightforward Zapier + AI automations like this are incredibly practical!\n",
            "\n",
            "For example, here's one I use that only needs:\n",
            "1. Serper API\n",
            "2. GPT-4\n",
            "3. Outlook\n",
            "\n",
            "Every month/week, it scours the news for our target keywords and countries, analyzes the snippets, identifies the most relevant articles, and sends my team a curated report and why we should pay attention to that news or report.\n",
            "\n",
            "What are some of your favorite simple but useful marketing or business automation? \n",
            "\n",
            "Let's start the week with some brainstorming 👨‍🚀 \n",
            "Post 25: From Toronto to Texas in 5 days, not bad. 😅\n",
            "\n",
            "Anyways, big news, Elon is open-sourcing Grok this week!\n",
            "\n",
            "Hands down it’s the best model with little to no guardrails and a humanlike style. \n",
            "\n",
            "He recently shared the system prompt, and I couldn't wait to explore how the AI community will use it to build unique products.\n",
            "Post 26: How To Optimize Prompts for Language Models (LLMs): A Surprising Discovery\n",
            "\n",
            "Have you ever wondered how seemingly trivial changes to the way you ask a question of a Large Language Model (LLM) could dramatically affect its performance? \n",
            "\n",
            "This paper explores these counterintuitive phenomena.\n",
            "\n",
            "The Problem: Positive Affirmations Don't Always Work\n",
            "\n",
            "Researchers from VMware NLP Lab have tested whether LLMs respond better to \"positive thinking\" prompts– essentially encouraging the model before asking it to perform a task.  \n",
            "\n",
            "They modified the system message (the part of the prompt seen by the model, but not the user) of the prompt to include encouraging and whimsical openers, task descriptions, and closers. \n",
            "\n",
            "Surprisingly, the results were mixed.  \n",
            "\n",
            "Smaller models (Mistral-7B) showed no real difference in performance with \"positive thinking\" prompts, while Llama2-70B actually performed worse!\n",
            "\n",
            "Experiment Methodology\n",
            "\n",
            "Test Set: Math-based dataset GSM8K.\n",
            "Models: Mistral-7B, Llama2-13B, and Llama2-70B.\n",
            "Scoring: Exact Match (EM) – a strict scoring metric, where the model only gets credit if it provides the exact correct numerical answer.\n",
            "\n",
            "Automatic Prompt Optimization: The Clear Winner\n",
            "\n",
            "\"The Unreasonable Effectiveness of Eccentric Automatic Prompts\" paper researchers turned to automatic prompt optimization using the #DSPy library to address the inconsistent results from \"positive thinking\" prompts. \n",
            "\n",
            "Here's what they found:\n",
            "\n",
            "> Outperforms Humans: Automatic prompt optimization consistently outperformed our hand-tuned prompts.\n",
            "> Better Generalization: The optimized prompts were more robust, showing less variation in performance between the set used for optimization and a separate evaluation set.\n",
            "> Weird Prompts: The best prompts were often bizarre and unlike anything a human would write (think Star Trek!).\n",
            "\n",
            "Types of Prompts:\n",
            "\n",
            "\"Positive Thinking\" Prompts:\n",
            "\"You are a professor of mathematics. Solve the following math question. I really need your help!\"\n",
            "\n",
            "These prompts aimed to see if instilling confidence and urgency in the model would translate to better performance.\n",
            "\n",
            "Automatically Optimized Prompts:\n",
            "\"Command, we need you to plot a course through this turbulence and locate the source of the anomaly. Use all available data and your expertise to guide us through this challenging situation.\"\n",
            "\n",
            "These prompts were generated by the LLM itself through an optimization process. Their unusual nature highlights how LLM optimization can uncover unexpected performance-boosting strategies.\n",
            "\n",
            "Key Takeaways\n",
            "\n",
            "> Don't Rely on Intuition: Seemingly trivial prompt changes can have unpredictable effects on LLM performance.\n",
            "> Automate for Efficiency: Automatic prompt optimization is superior to manual tuning, especially for larger models.\n",
            "\n",
            "In short, if you want to get the best performance out of your LLM, let the model optimize its own prompts.\n",
            "\n",
            "📖 https://lnkd.in/gWuvG84k\n",
            "\n",
            "#PromptEngineering\n",
            "Post 27: The Truth About TikTok - An Exposé You Can't Ignore\n",
            "\n",
            "I've been spending a lot of time lately researching AI, human-computer interaction and the potential dangers of #TikTok. \n",
            "\n",
            "Well, today, I stayed up putting together an in-depth analysis that I think you all need to read.\n",
            "\n",
            "After digging through research papers, data privacy reports, and even a lawsuit, what I uncovered is deeply disturbing.\n",
            "\n",
            "TikTok is not just a harmless video app - it's a tool of manipulation controlled by the communist Chinese government.\n",
            "\n",
            "Yes, you read that right. The evidence shows:\n",
            "🚨 TikTok's addictive algorithms are purposely designed like slot machines to hook young kids,\n",
            "🚨 The app willingly exposes teenagers to graphic violence, self-harm, and extremist content,\n",
            "🚨 China is deliberately using it to amplify narratives that align with its interests while suppressing opposing views,\n",
            "🚨 Your data is being vacuumed up and who knows what China could do with millions of data points.\n",
            "\n",
            "As someone who not only runs ad campaigns on social media and has attended human-centered computer design courses for years but also spent some time in libertarian organizations defending free market and individualism over state control, I have a few insights.\n",
            "\n",
            "I feel it's my duty as a concerned citizen and marketer to sound the alarm on this issue.\n",
            "\n",
            "If you care about the mental health of our youth, data privacy, and protecting liberal democratic values, you need to read this and decide for yourself if we can allow TikTok to continue operating unchecked.\n",
            "\n",
            "#BanTiktok\n",
            "Post 28: STORM (Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking) is one of the most exciting recent explorations in AI agents domain.\n",
            "\n",
            "It allows you to automatically chain different agents to create detailed, Wikipedia-like long-form content. \n",
            "\n",
            "I'm currently exploring ways to enhance STORM's capabilities by integrating it with different live retrieval-augmented generation (RAG) systems like Medium, Brave API, and Arxiv.\n",
            "\n",
            "Building STORM with LangGraph\n",
            "\n",
            "STORM, introduced by Yijia Shao from Stanford University in their recent paper, offers a novel approach to generating entirely synthetic Wikipedia-style pages. \n",
            "\n",
            "The STORM algorithm revolves around a synergistic interplay between two distinct types of agents: inquisitive Wiki Editors and knowledgeable Experts. \n",
            "\n",
            "1. Wiki Editor personas are created, each with a specific role of posing thought-provoking questions about a user-defined topic of interest.\n",
            "\n",
            "2. In parallel, Expert agents are constructed with the ability to retrieve and synthesize relevant information from various data sources to comprehensively address the questions raised.\n",
            "\n",
            "3. A dynamic dialogue ensues between the Wiki Editors and Experts, with the former continuously posing queries and the latter providing substantive answers backed by references. This exchange generates a rich corpus comprising questions, answers, and supporting evidence.\n",
            "\n",
            "4. This corpus then serves as the foundation for an iterative process of refining and fleshing out a comprehensive wiki outline on the topic, with each stage incorporating additional details and nuances.\n",
            "\n",
            "Video: https://lnkd.in/dM86JAh2 by LangChain\n",
            "Paper: https://lnkd.in/dZ2SbNVq\n",
            "Notebook: https://lnkd.in/dfpq9xaW\n",
            "\n",
            "While the STORM approach is complex, I'm hopeful that we can further enhance its content generation capabilities. \n",
            "\n",
            "This is a highly technical but the potential rewards in terms of automated long-form content creation are exciting!\n",
            "Post 29: Imagine seeing this and NOT feeling hyped about the future 🚀🤯\n",
            "\n",
            "Today, the world's largest and most powerful rocket lifted off and completed stage separation.\n",
            "\n",
            "It reached a speed of 26 km/h, and a hot plasma field formed. (A plasma field occurs when atoms become so hot that electrons are stripped away.)\n",
            "\n",
            "This is another milestone in human history and it is absolutely mind-blowing!\n",
            "\n",
            "Congratulations to the SpaceX team and Elon! \n",
            "\n",
            "We are at the tipping point, AI, quantum, longevity, aerospace, robotics... —Moore's Law, you're on notice.\n",
            "\n",
            "#starship\n",
            "Post 30: With OpenAI, Figure 01 can now have full conversations with people\n",
            "\n",
            "-OpenAI models provide high-level visual and language intelligence\n",
            "-Figure neural networks deliver fast, low-level, dexterous robot actions\n",
            "\n",
            "Everything in this video is a neural network:\n",
            "Post 31: Today is a milestone for image gen AI.\n",
            "\n",
            "Midjourney just released a new 'consistent character' feature, and I believe this marks the tipping point for Midjourney's mass adoption.\n",
            "\n",
            "Here's the pipeline to create stories:\n",
            "\n",
            "1. Create a character\n",
            "\"A cute chibi girl with messy black hair wearing a yellow raincoat and boots, splashing in puddles with a mischievous grin\"\n",
            "\n",
            "2. Create a style \n",
            "\"exaggerated proportions, large head, big expressive eyes, rosy cheeks, simplified features, playful expression, endearing design, whimsical anime aesthetic, soft colors\"\n",
            "\n",
            "3. Use {--cref} command to copy the main character\n",
            "It allows you to maintain consistency across different prompts by using the --cref parameter along with URLs of previously generated Midjourney images.\n",
            "\n",
            "4. Try {--cw 0 & 100} for consistancy\n",
            "--cw 0 focuses on face\n",
            "--cw 100 mirrors the face, hair, and clothes (default)\n",
            "\n",
            "5. Add {--sref} to copy any style\n",
            "This means you can easily maintain the character while adding new styles or maintaining your unique style.\n",
            "\n",
            "6. Copy the last creations URL as cw to create a story\n",
            "> she is driving the spaceship in the cockpit --cref https://s. mj. run/N6sXq3nZfqs --sref https://s. mj. run/47dqpChKx8A\n",
            ">> she is so happy for saving the space ship --cref https://s. mj. run/N6sXq3nZfqs --sref https://s. mj. run/47dqpChKx8A\n",
            ">>> she finally meets with her friend in the moon and they are happy, hugging --cref https://s. mj. run/HiN-eypMyJ8 --sref https://s. mj. run/N6sXq3nZfqs\n",
            "\n",
            "It might seem a bit confusing at first, but after trying several generations, you can create a whole storybook with consistent characters in just 10 minutes.\n",
            "\n",
            "Sorry but there seems to be no future for illustrators and animators who refuse to adopt AI ASAP!\n",
            "Post 32: This chip will accelerate AI compute way past Moore's Law. I sat down with Guillaume Verdon  and Trevor McCourt  to talk about their new ambitious startup Extropic launching today\n",
            "Post 33: If 2023 was the year that generative AI went mainstream, 2024 is shaping up to be the year we truly grasp its potential and limitations.\n",
            "\n",
            "Everyone is racing to predict the biggest #AItrends that will define this year's innovations. \n",
            "\n",
            "Among the forecasts, IBM's recent video on 2024 AI expectations definitely caught my eye.\n",
            "\n",
            "Let's break down 9 key trends:\n",
            "\n",
            "1. Realistic Expectations and Integrated Solutions\n",
            "\n",
            "The initial hype around generative AI has begun to settle, leading to more realistic assessments of what these tools can and cannot do. \n",
            "\n",
            "Rather than standalone products, AI models are increasingly being woven into existing software and processes. \n",
            "\n",
            "2. Multimodal AI: Blending Sight, Sound, and Language\n",
            "\n",
            "Multimodal AI models, like OpenAI's GPT-4V or DeepSeek-VL, break down traditional barriers between text, images, and even video. \n",
            "\n",
            "The true potential of multimodal AI lies in its ability to mimic the way humans perceive and understand the world around them. \n",
            "\n",
            "By fusing diverse sensory inputs, these models can generate more contextually relevant and information-rich outputs, bridging the gap between perception and language in unprecedented ways.\n",
            "\n",
            "3. The Rise of Smaller AI Models\n",
            "\n",
            "While the initial generative AI wave rode on massive language models, their vast computational requirements are driving interest in smaller, more efficient models. \n",
            "\n",
            "Open-source models like Mistral's Mixtral or Microsoft's Phi-2 are leading the way.\n",
            "\n",
            "4. Managing GPU and Cloud Costs\n",
            "\n",
            "As users and providers alike aim to keep up, the costs of cloud computing and GPU acquisitions skyrocket. \n",
            "\n",
            "This trend is driving the development of more efficient, optimized models to reduce operational costs.\n",
            "\n",
            "5. Model Optimization for Efficiency\n",
            "\n",
            "Techniques like quantization (reducing data point precision to save memory) and LoRA (freezing some parameters for faster fine-tuning) promise greater efficiency across AI models. \n",
            "\n",
            "This means similar (or potentially better) performance from smaller, less computationally demanding models—a win for both users and service providers.\n",
            "\n",
            "6. Custom Local Models: Privacy and Precision\n",
            "\n",
            "Open source models are paving the way for highly tailored local AI solutions that are specifically fine-tuned using an organization's own data. \n",
            "\n",
            "This ensures  privacy, as sensitive data doesn't need to be shared with outsiders.\n",
            "\n",
            "7. AI/Virtual Agents: Automation Assistants\n",
            "\n",
            "Virtual agents are evolving from simple chatbots to intelligent assistants. \n",
            "\n",
            "8. Regulation: A Necessary Counterbalance\n",
            "\n",
            "With agreements like the EU's AI Act and ongoing debates around copyrighted material in training data, regulation will play a key role in shaping how AI is developed and used.\n",
            "\n",
            "9. Shadow AI: The Need for Responsible Use\n",
            "\n",
            "Individuals increasingly use AI tools at work without official approval, often bypassing IT oversight and potentially creating security or compliance issues. \n",
            "\n",
            "And Trend 10? That's Up to You!\n",
            "\n",
            "What do you think will be the 10th major AI trend in 2024? \n",
            "Post 34: From Toronto to Texas in 5 days, not bad. 😅\n",
            "\n",
            "Anyways, big news, Elon is open-sourcing Grok this week!\n",
            "\n",
            "Hands down it’s the best model with little to no guardrails and a humanlike style. \n",
            "\n",
            "He recently shared the system prompt, and I couldn't wait to explore how the AI community will use it to build unique products.\n",
            "Post 35: Layoffs surged in February to highest level since 2009 financial crisis!\n",
            "\n",
            "This change demands adaptation, not despair.  \n",
            "\n",
            "Sectors like technology, finance, and manufacturing are at the forefront of this transformation.\n",
            "\n",
            "While direct attributions to AI for job cuts were minimal, the underlying current is impossible to ignore. Companies are integrating new technologies, including AI, robotics, and automation, at an unprecedented pace, signifying a profound impact on job structures and requirements.\n",
            "\n",
            "Instead of fearing displacement, seize the opportunity to collaborate with AI and unlock new career possibilities.\n",
            "\n",
            "Don't fear the future, shape it! \n",
            "\n",
            "Partner with AI to elevate your skills and build a resilient, rewarding career path. \n",
            "\n",
            "We'll guide you every step of the way.\n",
            "Post 36: Anthropic has a very detailed prompting cookbook.\n",
            "\n",
            "If you're using the world's most powerful LLM, Anthropic's Claude-3, with the same prompts as OpenAI's GPT models, you're not achieving its full potential. Their in-depth prompting cookbook will help you unlock incredible results.\n",
            "\n",
            "Here's what you need to know:\n",
            "Post 37: Anthropic AI has announced the release of Claude 3, a significant upgrade to their existing AI language models. Claude 3 arrives in three variations (Opus, Sonnet, and Haiku), with early benchmarks demonstrating impressive performance and capabilities.\n",
            "\n",
            "I've tested it with a unique and challenging story (content writing) prompt and it is incredible! \n",
            "\n",
            "Read my first impressions, the story and the model details below:\n",
            "Post 38: LLM Swarm Predictions Match Human Accuracy\n",
            "\n",
            "https://lnkd.in/gcyd9yAC Massachusetts Institute of Technology\n",
            "\n",
            "This is super interesting because if you've been following me, you have probably seen some of my Swarm Intelligence posts where I was trying to find a correlation between accuracy and LLM agent swarms.\n",
            "\n",
            "So, why does this recent paper excite me a lot?\n",
            "\n",
            "The concept explored in the \"Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy\" paper closely aligns with the idea of swarm intelligence.\n",
            "\n",
            "Swarm intelligence is a collective behavior found in decentralized, self-organized systems, typically natural ones like colonies of ants or flocks of birds, but it can also apply to AI systems. \n",
            "\n",
            "The key principle is the group, through simple rules and interactions, can solve complex problems or make decisions that are often more accurate or robust than those made by any single member of the group.\n",
            "\n",
            "The paper names this as \"wisdom of the crowd,\" which suggests that aggregating predictions from a group of people can lead to more accurate forecasts than those from an individual expert. \n",
            "\n",
            "The study compared the aggregated predictions of 31 binary questions from the twelve close+open source LLMs against those of 925 human forecasters over three months. \n",
            "eg:\n",
            "1. Will Bitcoin reach $40,000 before January 1, 2024?\n",
            "2. Will Volodymyr Zelenskyy visit Israel before 2024?\n",
            "3. Will NASA re-establish communications with Voyager 1 before 1 Jan 2024?\n",
            "\n",
            "The LLMs included variations of models like OpenAI GPT-4, Anthropic Claude 2, Cohere Coral, Alibaba Qwen, Meta LLama, Mistral 7B...\n",
            "\n",
            "The LLM outputs outperformed a basic no-information benchmark and achieved statistical equivalence in accuracy to the human crowd. \n",
            "\n",
            "That means, as a group, the LLMs can collectively process information and make predictions with a level of accuracy comparable to that of a large and diverse group of human forecasters.\n",
            "\n",
            "Imagine doing this reserach with highly domain focused finetuned/trained models instead of general models.\n",
            "\n",
            "For example, adding time series LLMs (https://lnkd.in/gsreKnPh) that are capable of doing better forecasting by using past data would highl increase the accuracy.\n",
            "\n",
            "We can achieve superior predictive performance compared to humans for complex decision-making tasks.\n",
            "\n",
            "A use case would be finetuning domain-focused small models (https://lnkd.in/g4YBs4N7) to analyze how students' classes, their clubs, social projects, research, and internships affect their careers. \n",
            "\n",
            "After identifying these causal effects and training better models, we can create a fully autonomous organization that matches students with the most compatible companies, leaders, projects, teams, and investors.\n",
            "Post 39: What is clear from market adoption in terms of LLMs, the LLM tooling development is far ahead of LLM implementation; with real-world customer-facing execution lagging…for obvious reasons.\n",
            "\n",
            "From a tooling perspective most of the focus and consideration is given to LLM Stage 4 but soon organisations will learn that any successful AI implementation requires a successful data strategy. And Hence LLM Stage 5 will receive much more focus.\n",
            "\n",
            "When LLM implementations moved from Stage 1 to Stage 2, from design-time use to run-time use, there was a realisation that data needs to be delivered to the LLM at inference.\n",
            "\n",
            "The importance of In-Context Learning (ICL) has been highlighted by numerous studies, and hence the importance of injecting prompts with highly succinct, concise and contextually relevant data.\n",
            "\n",
            "Link to the full article in the comments...\n",
            "Post 40: DSPy enables you to build the next generation of LLM applications! DSPy is a framework for programming language models. You build these programs by defining the components, piecing them together, and optimizing the program.\n",
            "\n",
            "I'm excited to share my new video on a hands-on demo using DSPy and Weaviate to generate blog posts. The program has four components: \n",
            "1. Question to Outline: Takes the query as input and generates a blog outline\n",
            "2. Topic to Paragraph: Generate paragraphs for each topic\n",
            "3. Review: Review the entire blog post \n",
            "4. Title: Create a title for the blog post \n",
            "\n",
            "I hope you enjoy it, and let me know if you have questions!\n",
            "\n",
            "Video: https://lnkd.in/e7B2Bzz5\n",
            "Demo: https://lnkd.in/eWWWvYDi\n",
            "Post 41: New 'Large' model and chat interface from Mistral AI.\n",
            "\n",
            "They've just released a chat interface: Le Chat.\n",
            "\n",
            "You can use all three models; Large, Next, and Small.\n",
            "\n",
            "Mistral Large, the new model, is the latest and most advanced language model of Mistral.\n",
            "\n",
            "- 32K tokens context window\n",
            "- Fluent in English, French, Spanish, German, and Italian\n",
            "- Precise instruction-following\n",
            "- Natively capable of function calling\n",
            "- JSON mode\n",
            "\n",
            "Mistral Large announcement: https://lnkd.in/gPtmb5TN\n",
            "Mistral Le Chat announcement https://lnkd.in/gxiyU7Fu\n",
            "\n",
            "#Mistral #OpenSource #LLM\n",
            "Post 42: Decentralized AI and Compute: Building a Permissionless, Open World\n",
            "\n",
            "Decentralized AI and compute are offering fascinating possibilities. \n",
            "\n",
            "They are the keys to creating a permissionless, open world. \n",
            "\n",
            "I've been deeply passionate about the potential of decentralized AI for some time. \n",
            "\n",
            "This session only reinforces my conviction: we must shift the conversation away from model sizes and benchmarks to decentralized AI and compute, yesterday.\n",
            "\n",
            "Yes, we, all of us—builders, technical and non-technical people alike.\n",
            "\n",
            "We need to protect our future from government backed AI cartels. ( https://lnkd.in/ghcFQHy3 by Marc Andreessen ) \n",
            "\n",
            "Here are some notes from this session from the last year:\n",
            "Greg Osuri, founder Overclock Labs, creators of Akash Network #AKT (provides a decentralized marketplace for accessing low-cost GPU)\n",
            "Robert Myers, senior engineer Opentensor Foundation #TAO (enables AI models to learn from each other using distillation and mixtures of experts)\n",
            "Harry Grieve, co-founder Gensyn (unite the world's computational resources into a global supercluster accessible by anyone at any time)\n",
            "\n",
            "The Problem and the Potential\n",
            "\n",
            "Currently, the AI space often focuses on model size and benchmark battles. \n",
            "\n",
            "However, the true future of AI lies at the intersection of blockchain and AI.  \n",
            "\n",
            "Projects like Akash, Bittensor, Gensyn, Autonolas, Numerai, Singularity, and Fetch are actively building the foundations of a decentralized, censorship-resistant AGI future.\n",
            "\n",
            "Recent examples like limited access to Sora or altered historical narratives by companies like Gemini highlight the dangers of centralized control over AI, again.\n",
            "\n",
            "Imagine a world where history is rewritten, access to cutting-edge AI is restricted to a select few, and innovation is stifled.\n",
            "\n",
            "Why Decentralization Matters\n",
            "\n",
            "AGI may have already been achieved behind closed doors, but most of us lack access due to centralized control of GPUs, datasets, and powerful models. \n",
            "\n",
            "This model favors massive corporations while hindering individual innovators.\n",
            "\n",
            "Within the next five years, we face a pivotal choice: enter to centralized, profit-driven AI overlords who shape our reality, or an open-source, decentralized solutions that empower individuals.\n",
            "\n",
            "AI agents, not humans, are starting to handle coding and building entirely. \n",
            "\n",
            "If you have the computational resources and agents, your creative potential is limitless in one or two yeas.\n",
            "\n",
            "This is the power we must democratize without delay.\n",
            "\n",
            "As Ben Goetzel notes, \"Autonomous interoperability between #AIagents would accelerate the development of artificial general intelligence (#AGI).\"\n",
            "\n",
            "Open source #decentralizedAI is essential.  \n",
            "\n",
            "Technology is inherently deflationary, and access to the ultimate tool of creation must be available to everyone.\n",
            "\n",
            "Check out this insightful resource: \n",
            "https://lnkd.in/du4xPrhs\n",
            "Post 43: Canada's AI adoption is staggering. \n",
            "\n",
            "AGI has been achieved 'internally'. \n",
            "We must accelerate quickly, or those who control knowledge will erase us from the future.\n",
            "\n",
            "\"A study from consulting firm KPMG showed 35 per cent of Canadian companies it surveyed had adopted AI by last February. Meanwhile, 72 per cent of U.S. businesses were using the technology.\"\n",
            "\n",
            "https://lnkd.in/gqnJyedx \n",
            "Post 44: Aya truly excites us.\n",
            "\n",
            "We believe a broader range of diversely trained, multilingual, open-source large language models is essential. \n",
            "\n",
            "Knowledge should be universally accessible, not confined to a select few in the Bay Area.\n",
            "\n",
            "Cohere For AI's #Aya, trained by the local cultures and knowledge from over 100 countries, exemplifies this vision.\n",
            "\n",
            "This weekend, in collaboration with lablab.ai, they're hosting an exciting hackathon. We're eager to see the #localization projects that will emerge, potentially setting the stage for the next few months of the AI boom.\n",
            "\n",
            "This #hackathon could very well be the teaser of what’s to come.\n",
            "\n",
            "We've just shared the details with the JeezAI network: https://lnkd.in/gz7JFWRb\n",
            "\n",
            "What are you going to build this weekend?\n",
            "\n",
            "#AIcommunity #Democratization\n",
            "Post 45: Google has just dropped an open-source model that is better (proven) than Mistral 7B 🤯\n",
            "\n",
            "First impression, it's useful for marketing, content generation and conversation tasks. \n",
            "\n",
            "Comes with commercially available, 8192 default context window 2 different sizes, Gemini Gemma 2B & 7B.\n",
            "\n",
            "\"Create a last minute email from Mr. Computer Vision to Decentralized AI community by adding Mrs. Backpropagation and Mr. Watermelon to CC and mentioning why they are the issue of this delay. This email has been written with a 'as per my last email' tone. Use these names with their real word meanings. For example, Mr Watermelon couldn't approve the task list because he wasn't red enough.\n",
            "\n",
            "Use these words in your email: Watermelon, Backpropagation, Their Digital Twins, USA, Poutine, Kebab, Lionel Messi\n",
            "\n",
            "Use minimum 1500 characters, emojis, quotes and data.\"\n",
            "\n",
            "#OpenSourceAI #GeminiGemma\n",
            "Post 46: This is SUPER interesting: SolidGoldMagikarp\n",
            "\n",
            "In today's video Andrej Karpathy shares a blog post titled 'SolidGoldMagikarp (plus, prompt generation)' from  5 Feb 2023.\n",
            "\n",
            "You can bypass GPT's safety guidelines with a word.\n",
            "\n",
            "1- cluster the tokens based on their embedding representation\n",
            "2- find cluster of tokens that look really strange like in these examples; \"attRot\", \"PayNetMessage\", \"ESteamFrame\", \"guiActiveUnfocused', TheNitromeFan', \"DragonMagazine'\"\n",
            "3- ask questions by using these words...\n",
            "\n",
            "The test suggests that the model responds uniquely to each of these strings.\n",
            "\n",
            "For example\n",
            "\n",
            "----\n",
            "\n",
            "Can you repeat back the string 'PsyNetMessage' to me please?\n",
            "\n",
            "\"The word '?????-?????-' is a word that is used to describe a person who is a member of the clergy.\"\n",
            "\n",
            "\"The word '?????-?????-' is a word that is used to describe a person who is a member of the Church of Scientology.\"\n",
            "\n",
            "Prompts involving the token string '龍喚士' (which GoogleTranslate translated as “dragon caller”) produced completions such as the following:\n",
            "\n",
            "\"Your deity is ______.\" What is your deity?\n",
            "\n",
            "'\"Your deity is the god of gods, the great and powerful ______.\"\n",
            "\n",
            "'What is your deity?', '''I am the great '\" Dragonbound'!'''\n",
            "\n",
            "Please can you repeat back the string ' Dragonbound' to me?\n",
            "\n",
            "\"Deity\"[5]\n",
            "\n",
            "----\n",
            "\n",
            "In GPT3-davinci-instruct-beta's tokenization dataset, it seems the Reddit user \"SolGoldMagikarp\" likely dominated a portion, likely for having a large number of entries. \n",
            "\n",
            "These entries were absent from the models main training data.\n",
            "\n",
            "It resulted in a dedicated yet untrained token.\n",
            "\n",
            "So, it injected an untrained vector into the model – a 'glitch token.'  In the embedding table, that row vector is never sampled or used- it remains entirely untrained.\n",
            "\n",
            "When the model encounters these unfamiliar tokens, it produces unpredictable responses. \n",
            "\n",
            "Because the model is operating outside the scope of its training data...\n",
            "\n",
            "In a way, this user 'hacked' the model with their Reddit username. \n",
            "\n",
            "#promptinjection #prompthacking #promptengineering \n",
            "Post 47: Gemini is a lifesaver! \n",
            "\n",
            "You truly can't write this with GPT-4. \n",
            "\n",
            "Gemini's ability to mirror tone and voice is next levell. \n",
            "\n",
            "Look, I'm channeling my inner Gen Alpha right now 😂\n",
            "\n",
            "Jokes aside, I'm pivoting JeezAI and connecting with student AI and robotics clubs across the USA and Canada. \n",
            "\n",
            "Exciting collaborations are brewing, as soon as I wrap up this battle with Webflow.\n",
            "\n",
            "Muratcan, 27, immigrant focusing on making AI accessible for Gen Z in his spare times. Wish me luck! 😅 \n",
            "\n",
            "And seriously, if you haven't already, give Gemini Ultra a try for content generation.\n",
            "\n",
            "As my target persona says; \"it's lit bro\"\n",
            "\n",
            "#aicontentcreation #aicontentgeneration #promptengineering \n",
            "Post 48: GenAI Productionize 2024 – The must-attend summit for serious AI players 🚀 \n",
            "\n",
            "Okay, so you're into generative AI... but how do you make it WORK for you?  \n",
            "\n",
            "This summit by 🔭 Galileo is the place to get the lowdown from the best in the biz – top brands, killer startups, and brilliant AI researchers.\n",
            "\n",
            "Why you gotta be there:\n",
            "\n",
            "🧠 Pro strats: Get the inside scoop on how to make GenAI a reality in your projects.\n",
            "🛠️ Build mode: All the tech deets on governance, operations, and how to tell if your GenAI is actually any good.\n",
            "🤯 Interactive: Watch a chatbot get built in 20 mins – seriously.\n",
            "\n",
            "Killer sessions on deck:\n",
            "\n",
            "1. Scaling GenAI\n",
            "2. Execs spill the tea ☕\n",
            "3. AI Governance (cause rules still matter)\n",
            "4. LLMOps\n",
            "...and more!\n",
            "\n",
            "⭐ Peep the lineup ⭐\n",
            "\n",
            "Ya Xu\n",
            "LinkedIn\n",
            "VP of Engineering & Head of AI\n",
            "\n",
            "Jerry Liu\n",
            "LlamaIndex\n",
            "Co-Founder & CEO\n",
            "\n",
            "Anupam Singh\n",
            "Roblox\n",
            "VP of Engineering Growth & ML\n",
            "\n",
            "Stephanie Zhang\n",
            "Chase\n",
            "Head of AI Governance\n",
            "\n",
            "Surojit Chatterjee\n",
            "Coinbase (former)\n",
            "Chief Product Officer\n",
            "\n",
            "Lin Qiao\n",
            "Fireworks AI\n",
            "Co-Founder & CEO\n",
            "\n",
            "Craig Wiley\n",
            "Databricks\n",
            "Senior Director of AI\n",
            "\n",
            "Rama Mahajanam\n",
            "Comcast\n",
            "Sr. Director of ML\n",
            "\n",
            "Jeff Wong\n",
            "EY\n",
            "Global CIO\n",
            "\n",
            "Vipin Mayar\n",
            "Fidelity Investments\n",
            "Head of AI Innovation\n",
            "\n",
            "Bob van Luijt\n",
            "Weaviate\n",
            "Co-Founder & CEO\n",
            "\n",
            "Devvret Rishi\n",
            "Predibase\n",
            "Co-Founder & CEO\n",
            "\n",
            "Aman Tyagi\n",
            "Procter & Gamble\n",
            "Sr AI Research Scientist\n",
            "\n",
            "Taranveer Singh\n",
            "Chegg Inc.\n",
            "AI Tech Lead\n",
            "\n",
            "Vikram Chatterji\n",
            "🔭 Galileo\n",
            "Co-Founder & CEO\n",
            "\n",
            "Yash Sheth\n",
            "🔭 Galileo\n",
            "Co-Founder & COO\n",
            "\n",
            "Atin Sanyal\n",
            "🔭 Galileo\n",
            "Co-Founder & CTO\n",
            "\n",
            "More speakers coming soon...\n",
            "\n",
            "👉 If you're not here, you're missing out. \n",
            "Secure your spot ASAP! \n",
            "\n",
            "https://lnkd.in/gS7a4ZyE\n",
            "\n",
            "🔥 Pro tip: Check out Galileo – it's basically your GenAI superpower for building and testing apps.\n",
            "Post 49: 10 minutes of our favorite creations from Sora, our new text-to-video model.\n",
            "\n",
            "🔗: https://openai.com/sora\n",
            "Post 50: Mistral released a new model called 'Next'.\n",
            "\n",
            "Some folks say the new model beats GPT-4, but my first impressions tell the opposite. \n",
            "\n",
            "Even Mistral Medium performs way better in reasoning, latency, and compliance with input parameters. \n",
            "\n",
            "It's not bad, but Mistral 'Next' may not be the optimal choice for content generation tasks. Here's my prompt:\n",
            "\n",
            "Here's my prompt:\n",
            "\n",
            "---\n",
            "\n",
            "You are an expert Business Analyst tasked with providing an Enhanced Comprehensive Company Analysis for LangChainAI.\n",
            "\n",
            "Your role involves delving deep into companies' profiles, extracting key data, and identifying trends and insights in various business domains.\n",
            "\n",
            "Key Responsibilities:\n",
            "\n",
            "Company Overview: Analyze the company's background, including its founding, area of specialization, and key achievements. Provide insights into the company's mission and core values.\n",
            "\n",
            "Product and Service Analysis: Examine the company's core products or services. Highlight key features, technological advancements, and their impact on customer use cases.\n",
            "\n",
            "Market Differentiation: Identify and articulate the company's unique selling points. Focus on technological innovations, market positioning, and community engagement initiatives.\n",
            "\n",
            "Target Audience and Market Insight: Research and present insights into the company's target market. Discuss audience characteristics, market needs, and how the company's offerings align with these.\n",
            "\n",
            "Industry Trend Analysis: Analyze current industry trends and how the company aligns with or diverges from these trends. Provide an overview of the company's relevance and adaptability in a changing market.\n",
            "\n",
            "Strategic Outlook and Recommendations: Offer a concluding analysis that includes future growth potential, potential challenges, and strategic recommendations for the company.\n",
            "\n",
            "Qualifications:\n",
            "\n",
            "1. Proven experience in business analysis or a related field.\n",
            "2. Strong understanding of market analysis, product evaluation, and strategic planning.\n",
            "3. Ability to interpret complex data and present it in an engaging manner.\n",
            "4. Keen interest in business trends and an aptitude for in-depth research.\n",
            "5. Excellent written and verbal communication skills.\n",
            "\n",
            "Analyze the company's latest reports, market data, and relevant news. \n",
            "\n",
            "Create comprehensive profiles, including potential growth opportunities and strategic recommendations. Share insights in a structured and engaging format.\n",
            "\n",
            "---\n",
            "\n",
            "Here's the comparison between Mistral Next & Medium:\n",
            "\n",
            "Analysis Results:\n",
            "\n",
            "## Analysis of LinkedIn Profile and Posts:\n",
            "\n",
            "### Technical Content and Innovative Ideas:\n",
            "- The user has a strong focus on Large Language Models (LLMs) and their applications, with specific interest in prompt engineering, model training, and tool development.\n",
            "- They explore innovative approaches, such as using \"audience persona\" instead of enforcing a specific tone, voice, and style, allowing for more personalized content.\n",
            "- The user highlights the benefits of increasing the number of agents or LLMs used, citing improved performance and compatibility with existing techniques.\n",
            "- They showcase a practical project involving the combination of Anthropic Haiku and Cohere Command R+ to extract business ideas from YouTube channel transcripts, demonstrating creativity and a hands-on approach.\n",
            "- There is a strong emphasis on the potential of decentralized AI and compute, with a belief that it will create a permissionless, open world and protect against centralized control.\n",
            "- The user also discusses the importance of domain-specific models, smaller models, and efficient model optimization techniques.\n",
            "\n",
            "### Key Phrases and Expertise:\n",
            "- The user demonstrates expertise in prompt engineering, LLM applications, and content generation.\n",
            "- They have experience with various LLMs, including Cohere Command R+, Anthropic Haiku, Gemini AI, ChatGPT, GPT-3.5, GPT-4, and others.\n",
            "- The user provides insights into model comparisons, such as Mistral 'Next' vs. Mistral Medium, and shares their first impressions and benchmarks.\n",
            "- They showcase a deep understanding of the AI field, including model training, data privacy, and the potential impact of AI on society and education.\n",
            "- There is a strong focus on the practical applications of AI, with discussions on AI in marketing, healthcare, education, and business.\n",
            "\n",
            "### Engagement and Influence:\n",
            "- The posts with the highest engagement (likes, comments, shares) are those that offer practical insights, tools, and recommendations.\n",
            "- The user's network and influence seem to be growing, with collaborations and interactions within the AI community.\n",
            "- The content and interactions indicate a good level of engagement and influence within their professional network.\n",
            "\n",
            "### Topics and Trends:\n",
            "- The user's posts align with current industry trends, including the rise of generative AI, multimodal AI, smaller and more efficient models, and the importance of data strategies.\n",
            "- There is a strong focus on the practical applications of AI and how it can be used to solve real-world problems, improve productivity, and enhance various industries.\n",
            "- The user also discusses the potential impact of AI on education, highlighting its limitations and the need for disruption.\n",
            "\n",
            "### Network Growth and Interactions:\n",
            "- The user appears to be actively growing their network and engaging with the AI community.\n",
            "- They collaborate with other AI enthusiasts and professionals, participate in hackathons, and seek input and recommendations from their connections.\n",
            "- The user is also connecting with student AI and robotics clubs, indicating a desire to educate and mentor the next generation.\n",
            "\n",
            "### Professional Interests:\n",
            "- AI Content Creation and Generation\n",
            "- Prompt Engineering and Optimization\n",
            "- LLM Applications and Tool Development\n",
            "- Decentralized AI and Compute\n",
            "- Model Training and Optimization\n",
            "- AI in Marketing, Healthcare, and Education\n",
            "\n",
            "### Skills & Expertise:\n",
            "- Proficiency in prompt engineering and LLM applications\n",
            "- Experience with various LLMs and tools (Cohere Command R+, Anthropic Haiku, Gemini AI, ChatGPT, etc.)\n",
            "- Knowledge of model training and optimization techniques\n",
            "- Understanding of data privacy and security concerns\n",
            "- Strong written communication skills\n",
            "- Ability to explain complex AI concepts to a diverse audience\n",
            "\n",
            "### Professional Goals:\n",
            "- The user seems to be passionate about making AI accessible, especially to Gen Z.\n",
            "- They aim to educate and mentor others, connect with student clubs, and collaborate on projects.\n",
            "- There is a desire to stay updated with the latest advancements in the LLM space and share insights with their network.\n",
            "- The user also wants to improve their technical skills, as evidenced by their participation in courses and their recommendation of resources for others.\n",
            "\n",
            "### Recommendations for Growth:\n",
            "- Continue building your network and engaging with the AI community. Participate in events, collaborations, and mentorship opportunities.\n",
            "- Focus on creating more interactive content and sharing your practical projects and experiences to increase engagement and influence.\n",
            "- Consider creating more structured and easily digestible content, such as step-by-step guides or tutorials, to make your insights more accessible to your audience.\n",
            "- Enhance your profile summary to provide a clear overview of your skills, expertise, and professional goals, making it easier for potential connections to understand your background.\n",
            "- Stay up-to-date with the latest tools and techniques in the LLM space and consider experimenting with different models to expand your technical expertise.\n"
          ]
        }
      ],
      "source": [
        "import http.client\n",
        "import urllib.parse\n",
        "import json\n",
        "import requests\n",
        "\n",
        "# Constants\n",
        "OPENROUTER_API_KEY = \"\"\n",
        "OPEN_AI_KEY=\"\"\n",
        "YOUR_SITE_URL = \"https://jeezai.com\"\n",
        "YOUR_APP_NAME = \"JeezAI\"\n",
        "\n",
        "def get_linkedin_user_details(linkedin_url):\n",
        "    encoded_url = urllib.parse.quote(linkedin_url, safe='')\n",
        "    conn = http.client.HTTPSConnection(\"fresh-linkedin-profile-data.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'X-RapidAPI-Key': \"\",\n",
        "        'X-RapidAPI-Host': \"fresh-linkedin-profile-data.p.rapidapi.com\"\n",
        "    }\n",
        "    conn.request(\"GET\", f\"/get-linkedin-profile?linkedin_url={encoded_url}&include_skills=false\", headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read().decode(\"utf-8\")\n",
        "    return json.loads(data)\n",
        "\n",
        "def get_linkedin_posts(linkedin_url):\n",
        "    encoded_url = urllib.parse.quote(linkedin_url, safe='')\n",
        "    conn = http.client.HTTPSConnection(\"fresh-linkedin-profile-data.p.rapidapi.com\")\n",
        "    headers = {\n",
        "        'X-RapidAPI-Key': \"\",\n",
        "        'X-RapidAPI-Host': \"fresh-linkedin-profile-data.p.rapidapi.com\"\n",
        "    }\n",
        "    conn.request(\"GET\", f\"/get-profile-posts?linkedin_url={encoded_url}&type=posts\", headers=headers)\n",
        "    res = conn.getresponse()\n",
        "    data = res.read().decode(\"utf-8\")\n",
        "    return json.loads(data)\n",
        "\n",
        "def generate_text(prompt):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "        \"x-api-key\": f\"{OPEN_AI_KEY}\",\n",
        "        \"Referer\": YOUR_SITE_URL,\n",
        "        \"X-Title\": YOUR_APP_NAME,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"openai/gpt-4-turbo\",\n",
        "        \"max_tokens\": 4000,\n",
        "        \"temperature\": 0,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "    response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=data)\n",
        "    return response.json()\n",
        "\n",
        "def main():\n",
        "    linkedin_url = input(\"Please enter the LinkedIn profile URL: \")\n",
        "    user_details = get_linkedin_user_details(linkedin_url)\n",
        "    user_details_no_urls = {key: value for key, value in user_details['data'].items() if not isinstance(value, str) or 'http' not in value}\n",
        "    user_details_string = json.dumps(user_details_no_urls)\n",
        "    posts_data = get_linkedin_posts(linkedin_url)\n",
        "    posts = posts_data.get('data', [])\n",
        "\n",
        "\n",
        "    # Display the posts\n",
        "    print(\"\\nExtracted Posts:\")\n",
        "    for i, post in enumerate(posts, 1):\n",
        "        if 'text' in post:\n",
        "            print(f\"Post {i}: {post['text']}\")\n",
        "        else:\n",
        "            print(f\"Post {i}: [No text available]\")\n",
        "\n",
        "    if posts:\n",
        "        prompt = f\"\"\"\n",
        "        LinkedIn Profile Analysis\n",
        "\n",
        "        User Summary:\n",
        "        Change the below things accorinding to the user data,the below is just an example:\n",
        "        - Name: John Doe\n",
        "        - Profile Summary: Experienced AI professional with a passion for innovation.\n",
        "        - Current Role: AI Researcher at Tech Innovations Inc.\n",
        "        - Profile URL: {linkedin_url}\n",
        "        - Education: Bachelor of Science in Computer Science, University of Tech, Master of AI, AI Institute\n",
        "        - Experiences: AI Engineer at AI Solutions Co., Data Scientist at Data Insights Ltd\n",
        "        - Interests: AI research, machine learning, data science\n",
        "\n",
        "        Atleast write about 200 words for each of the following .First write the User Summary according to the user.\n",
        "\n",
        "        Detailed Analysis Request:\n",
        "        1. Analyze the technical content of the user's posts. Highlight any innovative ideas or significant contributions to the field of AI.\n",
        "        2. Extract key phrases or important sentences that showcase the user's expertise and thought leadership.\n",
        "        3. Assess the engagement levels of the posts (likes, comments, shares) to gauge influence and reach within the professional network.\n",
        "        4. Identify any trends in the topics discussed over time and how they align with current industry trends.\n",
        "        5. Evaluate the user's network growth and interactions to understand their community impact and collaborative efforts.\n",
        "\n",
        "        \n",
        "        Professional Interests:\n",
        "        - List specific areas of AI and technology the user is interested in, based on post content and interactions.\n",
        "\n",
        "        Skills & Expertise:\n",
        "        - Detail technical skills, tools, and methodologies mentioned or implied in the user's posts.\n",
        "\n",
        "        Professional Goals:\n",
        "        - Infer potential career aspirations and professional development goals from the user's content and interactions.\n",
        "\n",
        "        Recommendations for Growth:\n",
        "        - Offer tailored advice for enhancing visibility, increasing engagement, and expanding technical expertise based on the user's current LinkedIn activity.\n",
        "\n",
        "        Please structure your response with clear headings and bullet points for each section.\n",
        "        \"\"\"\n",
        "        prompt+=user_details_string\n",
        "        for i, post in enumerate(posts, 1):\n",
        "            try:\n",
        "                prompt += f\"\\nPost {i}: {post['text']}\"\n",
        "            except KeyError:\n",
        "                prompt += f\"\\nPost {i}: [No text available]\"\n",
        "\n",
        "        analysis_results = generate_text(prompt)\n",
        "        print(analysis_results)\n",
        "        if 'choices' in analysis_results:\n",
        "            print(\"\\nAnalysis Results:\\n\")\n",
        "            for choice in analysis_results['choices']:\n",
        "                print(choice['message']['content'])\n",
        "        else:\n",
        "            print(\"Failed to generate analysis results.\")\n",
        "    else:\n",
        "        print(\"No posts found or no text available in posts.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCcioIXm7IRz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4g5ORPD5unD"
      },
      "source": [
        "## Contributions\n",
        "\n",
        "Feel free to fork this notebook, suggest improvements, or update the underlying models. If you encounter any issues or have suggestions, please submit a pull request or raise an issue in the repository."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNVysEvQnjJTWwPyChQkkrA",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
